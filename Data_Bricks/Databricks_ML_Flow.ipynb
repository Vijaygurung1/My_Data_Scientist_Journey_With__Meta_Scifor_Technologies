{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f6841-130c-4c7e-96f7-7af61211aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cluster in DataBricks - name it as - [ Vijaygurung1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e688b99-53b5-4edd-8f11-4a102bdfd06f",
   "metadata": {},
   "source": [
    "- Next Step : \n",
    "\n",
    "- Inside DataBricks Create the [ [ \"Cluster\" ] -13.3 ML meaning that machine learning.\n",
    "- If I go to create cluster I'm not going to create but when we choose the databricks runtime version always go with the machine learning.\n",
    "- If we are working with machine learning so that the necessary packages are already being installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551472c3-bc50-4fb9-951b-0a1cfee343df",
   "metadata": {},
   "source": [
    "# What is ML Flow ?\n",
    "\n",
    "- It is an open source platform to manage the emission learning life cycle\n",
    "\n",
    "- Including experimentation reproducibility deployment and a central model registry but all the things cannot be achieved.\n",
    "- In the community edition of databricks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7034fe1-0663-4271-88f5-b44eb7e3d935",
   "metadata": {},
   "source": [
    "# ML Flow Documentation Link :\n",
    "\n",
    "- URL : [ https://mlflow.org/docs/latest/index.html ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883efbdd-58ee-4446-986a-9b58bf149e0d",
   "metadata": {},
   "source": [
    "# DataBricks_ Documentation \n",
    "\n",
    "- URL - [ https://docs.databricks.com/en/index.html ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e65afe-2a1b-43ab-9872-869ee1d616e4",
   "metadata": {},
   "source": [
    "- If we are running Databricks Runtime version 7.1 or above, uncomment this line and run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b276398-73ab-459a-aa34-af26593a3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37de4b46-c6a3-4417-abf8-dc35e1eb2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are running Databricks Runtime version 6.4 to 7.0, uncomment this line and run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8872946-bab3-44d6-83ba-3f4adbfe14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b3823-c3d7-4de8-b958-4cedd009bcc1",
   "metadata": {},
   "source": [
    "- As we are dealing with ML stuffs, used the ML Databricks Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b761eaa-4dc1-4240-856d-7ac070d722af",
   "metadata": {},
   "source": [
    "- [ 13.3 LTS ML (includes Apache Spark 3.4.0, Scala 2.12) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa67b1-56c4-458d-b3a6-d6aaf6cb20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we need to do first is import required libraries here are some of the libraries import \"ML Flow\"\n",
    "\n",
    "# which is already installed and here I am importing something related to SQL so ml flow SQL on and there is matplotl pandas normally stops and\n",
    "# the data set I am going to use is "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f4699-b43d-47a8-84c9-63e663746c9f",
   "metadata": {},
   "source": [
    "- load diabetes from sk-learn diabetes\n",
    "\n",
    "- Mlflow already Installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec49ba-f262-4272-8d19-906ec21e6231",
   "metadata": {},
   "source": [
    "- Now we need to choose the data breaks runtime environment in order to proceed in your specific task and I am using this particular runtime.\n",
    "- So that we can also follow along when we create the cluster what we need to do first is import required libraries here are some of the libraries\n",
    "- import \"ML Flow\" which is already installed and here I am importing something related to Sk-learn so ml flow Sklearn on and there is matplotl pandas\n",
    "- normally stops and the data set I'm going to use is the load diabetes from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163591c-62e0-487a-9ae6-351a55158ce5",
   "metadata": {},
   "source": [
    "# Import required Libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d925da0a-63c4-44d3-b4ab-61543aa055c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow        \n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "from numpy import savetxt\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    " \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87cda3-4036-4a8d-a7ac-aeaaeb4b0e3c",
   "metadata": {},
   "source": [
    "- I just run this particular cell now and as we can see here it is running here because\n",
    "- I have already attached the cluster make sure cluster is connected before run any cells.\n",
    "- Now we need to know if it is installed or not ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b943564-75fd-4500-8ab2-d1067cb319f8",
   "metadata": {},
   "source": [
    "# \"ML Flow\" we can just roll \"Pip list\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6618af88-83aa-4a53-9d2b-11025f0bd7f0",
   "metadata": {},
   "source": [
    "- So here we can see that, [ \"pip List\" ] installed all the packages for us.\n",
    "\n",
    "- If I scroll little bit down this would be \"ML flow\" it is in the alphabetical order.So, we can go to the part where is the \"m\" there is \"ML Flow\" but it is \"skinny\"\n",
    "- why skinny is because if I go pip installed outcomes, it will show us all the different things about skinny.\n",
    "- if you want to know more things about what is skinny.\n",
    "\n",
    "- This is the URL Link : [ https://pypi.org/project/mlflow-skinny/ ] for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de3f66-f4d1-4d60-97cd-440e2ab337a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9802018-0a07-4817-a6dc-2d3f395f54d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I am going to do is provide, two examples one is about the \"regression\" and one is the one is the \"Classification model\".\n",
    "\n",
    "# And see what are the things that can be logged in the \"ML flow\" experiments by default here the normal things is that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6bf8d-acb5-44d5-a7cc-d3651da48194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data set I am taking the \"load diabetes data set\" which I imported here in this sale already upside."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78157a27-abdc-4955-890a-75afb205c1fc",
   "metadata": {},
   "source": [
    "# Explnation_below_Code\n",
    "\n",
    "- Now in the \"X\", we have the DB dot(.) data and \"Y\" is DB dot(.) Target that is how it works in machine learning.\n",
    "\n",
    "- There should be one where we train the data and one where we see the results for the prediction of the data.\n",
    "- So, we need to do the [ \"train test split\"].So, I am doing the train test split with the default things.\n",
    "- If we just hover on this part - [ \"X_train, X_test, y_train, y_test = train_test_split(X, y) \"] it will show me what are the things it takes by default\n",
    "-  Now, Lets run this below code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fc1b27-ff3d-44a5-96ec-5cf0bda65076",
   "metadata": {},
   "source": [
    "# Import the dataset from scikit-learn and create the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904064c-e0c3-4228-a042-bb45e4acdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = load_diabetes()\n",
    "X = db.data\n",
    "y = db.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d1e08-d151-4605-b47b-375f565639d9",
   "metadata": {},
   "source": [
    "# If want to know more things about [ \"Trend test split\" ] \n",
    "\n",
    "- Just provide \"train test split\" and two question marks and it will show me the documentation.\n",
    "\n",
    "- We can follow this split arrays or matrices into random train and test subsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d9395-3db0-418e-a2ce-00b203815195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fab551a-c2d6-4bf9-932e-74ceeab1b674",
   "metadata": {},
   "source": [
    "- Now, just to show what is the shapes we can say \"x\" dot(.) shape and \"Y\" dot(.) shape.\n",
    "\n",
    "- it will show us the shape of \"X data\" as well as the \"Y data\".\n",
    "\n",
    "- [ \"X and Y\" ] and by the way this is already in the numpy array.We do need to convert that we just need to be careful into this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f839abe-7130-438a-8ac2-c2b5d354c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76ad2b-91e3-47da-9bea-e859847470b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59edc737-8fd5-47b7-a869-5fa653eabdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513838c-1eb1-4357-827a-1bd0640d12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we are going to do here is Create a random forest model and log parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e315cc08-f3e6-4b47-827a-97b0d1cb9d1c",
   "metadata": {},
   "source": [
    "# What we are going to do here is Create a random forest model and log parameters\n",
    "\n",
    "- [MLFlow Python API](https://mlflow.org/docs/latest/python_api/index.html)\n",
    "\n",
    "- [Quickstart Guide Outside Databricks](https://mlflow.org/docs/latest/quickstart.html)\n",
    "\n",
    "# This are the link above here below i have explain that what this is explaning about.\n",
    "\n",
    "-  \"ML flow\" python API ml4 actually provides \"Python API's\". and\n",
    "\n",
    "- Here I am going to use \"SkLearn\" part, but as we can see here there are so many so we can follow specific ones so that,\n",
    "- it is just focusing on that particular \"API\" let's say that,if we if I want to go with the sklearn, if I go to the Sklearn we can see that \n",
    "- the \"SkLearn\" on \"ML flow dot(.) Sklearn on module provides an \"API\" for \"Logging and loading provides \"Scikit- Learn model\"\n",
    "- This module exports \"Scikit learn\" models with the following flavors.So, we can see there are different things and there are some of the\n",
    "- common matrixes for classifier and common Matrix is for regressor we will see this when we run the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45c3eb-9023-4266-85bc-eeffde3e61bd",
   "metadata": {},
   "source": [
    "# Enable autolog()\n",
    "# mlflow.sklearn.autolog() requires mlflow 1.11.0 or above.\n",
    "\n",
    "- Now I go here and how to actually log things \"ML Flow\" has this cool thing called \"Auto log\" all the parameters modal score and\n",
    "- the fitted model are automatically locked. I'm just trying to say that  [ \"MLFlow.sk-learn.autolog() ]. I am using skeleon here.\n",
    "- Because here I am focusing more into it.\n",
    "- As we run this still there is nothing here because no runs it we need to be focusing on this part.\n",
    "- when we run the experiments because this is where it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08e9f1-98ae-401a-a11f-06141aa16cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86308c4a-2925-43af-90a8-c3a82dd15147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With autolog() enabled, all model parameters, a model score, and the fitted model are automatically logged. \n",
    "\n",
    "- Now, what I am going to do is with [ mlflow.start_run(): ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca24ef-4999-4f43-97fd-221cac7e8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7dd4ea-169a-4e49-b288-60f263b66550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, these are the model parameters, we can provide whatever we want and there is this random Forest regressor.\n",
    "\n",
    "- I am providing the an estimator as [ \"100 maximum depth F6 maximum features and maximum features that is 3\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364025dd-d00d-485f-be97-018d1ec9bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d2805-d670-45e0-85b7-66f0f2c3c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now,then I am what I am doing here after this is just fitting that into the [ \"X strain and Y train\" ] and doing the predictions.\n",
    "\n",
    "- Just see what happens here now when, I run this particular cell.\n",
    "- This \"rumbling f917\" name given by default view the wrong and then it says okay this is the time it is using there is bootstrap and\n",
    "- training mean absolute error that is already being shown to us if we just click on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b6a77-f69b-42f4-b80c-1240c4c50eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With autolog() enabled, all model parameters, a model score, and the fitted model are automatically logged.  \n",
    "with mlflow.start_run():\n",
    "  \n",
    "  # Set the model parameters. \n",
    "  n_estimators = 100\n",
    "  max_depth = 6\n",
    "  max_features = 3\n",
    "  \n",
    "  # Create and train model.\n",
    "  rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "  rf.fit(X_train, y_train)\n",
    "  \n",
    "  # Use the model to make predictions on the test dataset.\n",
    "  predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c25fb73-892b-417d-bcf8-338d9218cbff",
   "metadata": {},
   "source": [
    "- Now can see that there are many things being used and also if we click on this model mean absolute error is 30 training.\n",
    "- mean square error is one ( 323 ),something like that it's already being logged here.But, I think instead of here what we can do is.\n",
    "- Go to the experiment UI it is already being logged in the UI, if I click this one this is inside databricks, we are not going outside.\n",
    "- this is the good part of databricks as I said we before because data breaks creators or the owners actually created\n",
    "- ml flow and that is made open source and they have integrated that into databricks for easiness as you can see here it says romling app.\n",
    "- if I click inside this okay it is given the wrong ID who is the user duration date it's finished or not what is the source and \n",
    "- what is the description we can provide here parameters okay what is the parameters as we we can see here these are the parameters of the model.\n",
    "- it's already being logged here and The Matrix we didn't write any code to create the metrics but that's a that's the good part of \"ml flow\"\n",
    "- that it automatically creates some metrics for us so as, we can see it says training \"R2 score\" the training score is ( 0.77 ) not bad and \n",
    "- we can just now tune our models or whatever we want to do to make this better as we use case and there are the tags.\n",
    "- so estimator class estimator name it is being default taken from there and there is artifacts also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1169f-673e-4ecd-99e9-a0679d0998f2",
   "metadata": {},
   "source": [
    "- what is artifacts if we go inside the model there is ml flow model there is already some of the artifacts being provided for us there is\n",
    "- conda ml file okay what is being used there is modal dot pickle there is \"python e and B ml\" file there is [\"requirement.txtimator.html\" ]\n",
    "- if we go to this model now as we can see the good part of this is the code Snippets below demonstrate how to make prediction using the logged model.\n",
    "- so we can there is already the code being provided to you in order to run this model. So we can use or predict on a spark data frame or \n",
    "- we can predict on a pandas data frame just copy this and then run the model.\n",
    "- if I go to the ml Pro Basics notebook, the regression part we get the idea how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a875436d-8705-4503-9ac7-767cdadde962",
   "metadata": {},
   "source": [
    "# Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59e05dd-549a-43bb-b95b-e08aa6dc0206",
   "metadata": {},
   "source": [
    "- what if we want to run with the classification problem let's say that I am importing some of the things just to not show me any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f4675-3ddb-497c-bf98-3042a492c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# To ignore all warnings, you can use the following line:\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ab4341-94ad-4ef6-9e00-43e3de848a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the normal things I'm loading in the data sets again from the SK-Learn, but I'm using \"load ID data set\".\n",
    "# I can run this classification model also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2bc81-2c8f-44fb-af0d-6bb33fe3ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba0a57-a193-457f-8d62-2888ddaeb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here,I will say here okay data is load [\"Irish\"] as before [ X is data Y ] is the target I will just run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f0d1c-9ca8-41aa-90e1-8aa41a2d14b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset (in this case, the Iris dataset for simplicity)\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d01abd-9c49-46cd-8d7a-662a8053686f",
   "metadata": {},
   "source": [
    "- I do the trend test split but now here I am giving the test ( size 0.3 ) random ( State 42 ) as I said before we can provide whatever we want \n",
    "- not the default one only if you hover on top of this it will show you all the different things here so I can run this one and \n",
    "- now I can just run this if I run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e74ee-fd37-41f9-89cc-f778ab907602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72482fb0-91b1-4ad6-a552-8d78f6e50052",
   "metadata": {},
   "source": [
    "- The different here what I'm trying to see is that is here I'm providing the wrong name as \"classifier\" because before by default \n",
    "- it created this rumbling f917 which might be confusing for us, what is this but if we provide unique name here this is \"classified\" in this\n",
    "- case only but as we can see here it shows classifier.So that we know that it is specific to that particular run so this is the classifier and\n",
    "- yeah we can even run the accuracy because there is already the white bread being shown us it says one okay always be careful if the equation \n",
    "- is one then it's not a good model but yeah well we might argue on that but that's how it should be if something is really really good.\n",
    "- then there must be something wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b164f0f-ece6-4a15-b2f6-0ed8792dbcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"classifier\"):\n",
    "    # Create a classifier (in this case, K-Nearest Neighbors)\n",
    "    clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bced9a-f07a-44a9-93a1-3c37e1c55090",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Now if we want to see what is there you can go to this particular experiment or classifier or if we go to the previous one also here experiments\n",
    "- if we go to the experiment and by the way this is one way how we can view this or next is we have experiments on the side here.\n",
    "- So if I run this experiment the same thing pops up here ml flow Basics because that is the file that we have used if we  go inside there is\n",
    "- two experiments wrong name so I can go with the classifier now so this is different than the previous one so if we go to The Matrix there are\n",
    "- more Matrix now being shown \n",
    "\n",
    "- so accuracy training and all different things that's the reason I'm saying we that it depends upon the model or the classification model or\n",
    "- the regression model or there are many apis as I showed we before based on that the Matrix are being locked so that it's easier for us to see.\n",
    "- so if we want to go to the accuracy Matrix okay it's accuracy is all the way here then we can even go and print okay what is the log loss.\n",
    "- if you want to go with us to remove these things from here that's it that we can even visualize from here I don't want to go through \n",
    "- this indeed depth but as you can see we can do the line smoothness and different things here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae5a8d-8914-49b1-9191-aaf003acd123",
   "metadata": {},
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b676f-be89-4868-9fce-82c7babe7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register models\n",
    "\n",
    "- URL - [ model registry](https://docs.databricks.com/en/mlflow/model-registry.html) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5e406f-9546-48f7-8ac0-29f1b19425e1",
   "metadata": {},
   "source": [
    "- let's say that I want to register the model just to show me that it does not work in the community Edition.\n",
    "- I said here log to modal is this one and I want to give the different name as the register model I run enter and then I want to register.\n",
    "- how to register it is \"ML flow dot(.)\" register model and I am providing the log to model and the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3dda1-7e9e-4312-98e2-d36d0dfa6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/672634f12f0c45179ebfc7945dd9081e/model'\n",
    "register_model_name = \"classifier-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020082a0-c249-4520-a0c2-68c42d5619c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This as it is already shown there also but I will just run this it will show us the error that permission denied modern registry is not enabled.\n",
    "# for organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83219125-3590-4ebc-ab48-fec164ca190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.register_model(logged_model, register_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e5692-3058-44aa-a71a-0d68ea82ba30",
   "metadata": {},
   "source": [
    "- we cannot register the model because in the free version we don't have the models icon here but in the premium ones there will be\n",
    "- the model icon so when we draw this store the model then that will be resistor I hope that is clear but this this cannot be used in the \n",
    "- free version of course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca3fbf-1bf5-4a71-8d45-0a0d7519924a",
   "metadata": {},
   "source": [
    "- So,  what they allow us to view all the different things and the good part is the UI here this is the best part which I also like.\n",
    "- when using databricks is because we can just go through this UI already in databricks and visualize all the different things without\n",
    "- having to configure it myself and but if we want to go with the \"ML Flow\" Part just explore the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c283294-d579-49e0-b7d0-2516be982483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
